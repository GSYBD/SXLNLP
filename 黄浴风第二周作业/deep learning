import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt

"""
输入一个十维的向量如果前五个相加大于后五个则为True，否则为False
"""

class TorchModel(nn.Module):
    def __init__(self, inputsize):
        super(TorchModel, self).__init__()
        self.linear = nn.Linear(inputsize, 3)  # 输出3个类别的logits
        self.activation = torch.sigmoid        # 激活函数为sigmoid
        self.loss = nn.CrossEntropyLoss()      # 交叉熵损失函数

    def forward(self, x, y=None):
        x = self.linear(x)                     # (batch_size, inputsize) -> (batch_size, 3)
        if y is not None:
            return self.loss(x, y)             # 预测值和真实值计算损失
        else:
            return x                           # 返回logits

# 随机生成一个10维向量，前五个大于后五个返回1，否则返回0
def build_sample():
    x = np.random.random(10)
    if sum(x[:5]) > sum(x[5:]):
        return x, 1
    elif sum(x[:5]) == sum(x[5:]):
        return x, 2
    else:
        return x, 0

def build_dataset(train_sample):
    dataset_X = []
    dataset_Y = []
    for _ in range(train_sample):
        x, y = build_sample()
        dataset_X.append(x)
        dataset_Y.append(y)
    return torch.FloatTensor(dataset_X), torch.LongTensor(dataset_Y)  # 修改为LongTensor

def evaluate(model):
    model.eval()
    test_sample_num = 1000
    test_x, test_y = build_dataset(test_sample_num)
    correct, wrong = 0, 0
    with torch.no_grad():
        y_pred = model(test_x)
        y_pred = torch.argmax(y_pred, dim=1)  # 取最大值的索引作为预测类别
        correct = (y_pred == test_y).sum().item()
        wrong = test_sample_num - correct
    print("正确个数：%d, 错误个数：%d, 正确率：%f" % (correct, wrong, correct / (correct + wrong)))
    return correct / (correct + wrong)

def main():
    batch_size = 20  # 每次训练样本的个数
    epoch_num = 20   # 训练轮数
    inputsize = 10   # 输入数据的维度
    train_sample = 5000  # 随机数据个数
    learning_rate = 0.01  # 学习率
    log = []
    # 建立模型
    model = TorchModel(inputsize)
    # 建立训练数据集
    train_x, train_y = build_dataset(train_sample)
    # 选择优化器
    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
    # 训练模型
    for epoch in range(epoch_num):
        model.train()
        watch_loss = []
        for batch_index in range(train_sample // batch_size):
            x = train_x[batch_index * batch_size : (batch_index + 1) * batch_size]
            y = train_y[batch_index * batch_size : (batch_index + 1) * batch_size]
            loss = model(x, y)
            loss.backward()  # 计算梯度
            optimizer.step()  # 更新权重
            optimizer.zero_grad()  # 梯度清零
            watch_loss.append(loss.item())
        print("-----------第%d轮，平均loss：%f" % (epoch + 1, np.mean(watch_loss)))
        acc = evaluate(model)
        print("-----------第%d轮，准确率：%f" % (epoch + 1, acc))
        log.append([acc, float(np.mean(watch_loss))])
        torch.save(model.state_dict(), "model.pt")
    # 画图
    plt.plot(range(len(log)), [l[0] for l in log], label="acc")  # 画acc曲线
    plt.plot(range(len(log)), [l[1] for l in log], label="loss")  # 画loss曲线
    plt.legend()
    plt.show()

def predict(model_path, input_vec):
    input_size = 10
    model = TorchModel(input_size)
    model.load_state_dict(torch.load(model_path))
    print(model.state_dict)

    model.eval()
    with torch.no_grad():
        result = model(torch.FloatTensor(input_vec))    #模型预测
        for vec, res in zip(input_vec, result):
            print("输入向量：", vec)
            print("预测结果：", res)
            print("预测类别：", torch.argmax(res, dim=0))
            print("预测概率：", torch.max(res, dim=0))
            print("--------------------")



if __name__ == "__main__":
    #main()
    test_vec = [[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],
                [1, 2, 3, 5, 2, 3, 5, 7, 8, 9],
                [1, 3, 3, 5, 2, 3, 5, 3, 0, 3]]
    predict("model.pt", test_vec)
