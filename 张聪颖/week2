# coding:utf8

import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt

# 创建一个简单的神经网络模型
class Net(nn.Module):
    def __init__(self, input_size, hidden_size, num_classes):
        super(Net, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)  # 全连接层1
        self.relu = nn.ReLU()  # ReLU激活函数
        self.fc2 = nn.Linear(hidden_size, num_classes)  # 全连接层2
    def forward(self, x):
        x = self.fc1(x)
        x = self.relu(x)
        x = self.fc2(x)
        return x



# 设置超参数
input_size = 10
hidden_size = 20
num_classes = 5
learning_rate = 0.001
num_epochs = 10


# 准备数据
X = torch.randn(100, input_size)  # 生成100个样本，每个样本有10个特征
y = torch.randint(0, num_classes, (100,))  # 生成100个标签，标签范围在0到num_classes之间


# 初始化神经网络模型和损失函数
model = Net(input_size, hidden_size, num_classes)
criterion = nn.CrossEntropyLoss()  # 交叉熵损失函数
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)


# 模型训练
for epoch in range(num_epochs):
    outputs = model(X)  # 前向传播
    loss = criterion(outputs, y)  # 计算损失
    optimizer.zero_grad()  # 梯度清零
    loss.backward()  # 反向传播
    optimizer.step()  # 更新参数
    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')



# 示例预测
def predict(model, input_data):model.eval()  # 评估模式
    with torch.no_grad():  # 禁用梯度计算
        input_tensor = torch.tensor(input_data, dtype=torch.float32)
        output = model(input_tensor) _, predicted = torch.max(output.data, 1)
        return predicted.numpy()




# 进行预测
sample_data = np.random.randn(1, input_size)  # 生成一个样本
predicted_class = predict(model, sample_data)
print(f'Predicted class for sample data: {predicted_class[0]}')










